---
title: "CSCI E-63C: Week 1 Assignment"
author: "Tony McGovern"
date: "5 September 2017"
output:
  html_document:
    toc: true
---

```{r setup, include=FALSE}
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
```

# Problem 1
In this problem, I measure the spread of the standard error of a sample mean by simulating a run of 5000 trials where different sized samples are drawn from normally distributed (mean of zero and standard deviation of 1) random variables. By plotting the sample standard deviation or standard error of the sample mean (SEM), one can see that as the number of samples increase, the SEM decreases.

```{r sem,eval=TRUE}
# different sample sizes we are going to try:
sample.sizes=c(3,10,50, 100, 500, 1000)

# we will use the vector below to keep the SD of the distribution of the means at each given sample size
mean.sds = numeric(0) 
m = numeric(5000) # I want to run a simulation of 5000 trials


# initiate the indexing variable to keep the results of the standard deviation of the distributions of means of a sample size N
j = 1

for ( N in sample.sizes ) { # try different sample sizes
  for ( i in 1:length(m)) {
      
    # 1) At each given N (i.e. in each iteration of the outer loop) you have to draw large number 
    # (e.g. 1000) of samples of size N from the distribution of your choice (e.g. normal, uniform, exponential, ...), calculate the mean of each of those samples and save them all into
    # a vector m.
    m[i]<-mean(rnorm(N))
  }
  # 2) Now, with vector m in hand, we want to characterize how much the sample mean fluctuates
  # from one experiment (experiment=taking a sample of N measurements) to the next. Instead of just
  # drawing a histogram, this time we will calculate the standard deviation of the distribution
  # represented by the vector m. Use function sd().

  # 3) save the result (sd of the distributions of the means for current N) into the vector means.sds.
  # You can use c() or you can use an indexing variable, in the latter case you will need to add it to the
  # code and increment properly
  mean.sds[j]<-sd(m)
  j = j + 1
}

```


Now visualize the simulations. Note how as the sample size increases, the SEM decreases:
```{r sem_plot}

# I use ggplot2 to visualize the data
# create a data frame with sample sizes as the vector of x coordinates and the standard deviations of the distribution of the sample means as a the vector of y coordinates
data<-data.frame(sample.sizes,mean.sds)

# define ggplot as a line graph + scatter plot
ggplot(data,mapping=aes(x=sample.sizes,y=mean.sds)) + 
  geom_line(color="grey") + 
  geom_point(shape=1,color="red") +
  
  labs(title="Measuring the Spread of a Distribution of Sample Means",
       subtitle="Simulating the decrease in the sample standard deviation from increasing sample sizes",
       x="Sampe Size",
       y="SEM") + 
  theme_linedraw()

```

# Problem 2
In this problem, I show that as the number of samples from a non-normal distribution increases, the sample distribution approximates a normal curve, thus illustrating the primary feature of the Central Limit Theorem. In other words, at a sufficiently large *N* number of samples, the sample distribution becomes normal and the sample mean or sum of the distribution will be approximately normal as well.

```{r clt,eval=TRUE}
rm(list=ls())

repeats = 1000 # the number of trials in our simulation
s.values=numeric() # we will use this vector to store the value of the sum in each experiment
y=character() # initiate y vector which will hold the N within the sample.sizes vector for each value in s.values

# different sample sizes we are going to try:
sample.sizes=c(2,5,7,10)

j = 1

for ( N in sample.sizes ) {

  for (n.exp in 1:repeats) { 
    
    y[j]<-as.character(N)
    
    # capture the sum of an independent N-number of samples from a uniform distribution
    s.values[j]<-sum(runif(N)) 
    j = j + 1
    
  }
}
```


Now visualize the trials. Note the number of sample sizes are shown above each histogram:
```{r unif_plot}

# I use ggplot2 to visualize the data
# create a data frame with a vector containing the sum of independent N-number of samples drawn from a uniform distribution
data<-data.frame(x=s.values,y=as.numeric(y))

# define the plot as a N-number of histogram show in a facet, where N is the number of sample sizes drawn from the uniform distribution
ggplot(data, aes(x=x)) + 
  geom_histogram(
    binwidth = 0.5,
    color="grey",
    fill='red') +
  facet_wrap(~y,ncol=2) + 
  labs(
    x="Sum of N-number of Samples from Uniform Distribution",
    y="Number of Trials",
    title="Increasing Sample Sizes and Distribution of a Random Variable",
    subtitle="As N increases, the distribution of samples sums from a uniform distribution becomes normal"
    ) +
  theme_linedraw()

```

As the the *N*-number of measurements from an arbitrary distribution becomes sufficiently large, the distribution of the sample mean gets closer to the true mean of the population. For example, if the population is assumed to be normally distributed, with a mean of zero, then as *N* number of samples from that population increases, the sample mean gets closer to zero.

Since the sample distribution approximates a normal distribution, the sample distribution can also be measured using parameters such as the mean and standard deviation. Put another way, even if the population distribution is non-parametric, at a sufficiently large *N*, the sample distribution becomes normal, characterized by a sample mean and sample standard deviation. It is from this feature that statistical tests and inferences can be made about a population.